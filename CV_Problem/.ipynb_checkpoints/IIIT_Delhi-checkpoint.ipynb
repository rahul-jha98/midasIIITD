{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nM5-ed7G7k8E",
    "outputId": "afd383d4-559d-4c01-c93a-b43e3c106f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Training on GPU..\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "  print(\"CUDA is not available. Training on CPU...\")\n",
    "else:\n",
    "  print(\"CUDA is available. Training on GPU..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMXAP8qb8598"
   },
   "source": [
    "## Image Loading\n",
    "\n",
    "We are using pickle a library to handle pkl file to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYoszVAs84QK"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_image.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSzQqO4TxdSd"
   },
   "outputs": [],
   "source": [
    "with open('test_image.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHBCof1O92wP"
   },
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRh8gI1793xI"
   },
   "outputs": [],
   "source": [
    "with open('train_label.pkl', 'rb') as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ9hUKzd-JaM"
   },
   "outputs": [],
   "source": [
    "label = np.array(label)\n",
    "label[label == 6] = 1\n",
    "label = label.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQze4AD8BLlO"
   },
   "source": [
    "#### Converting the data to numpy array\n",
    "\n",
    "We are converting the data from list to numpy array for easy manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUc44_tauwul"
   },
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUM2GsmGtS_x"
   },
   "outputs": [],
   "source": [
    "data2 = np.array(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sxWMlE3BSGA"
   },
   "source": [
    "#### Reshaping the data to form an image\n",
    "\n",
    "We reshape the 784 sized vector to 28x28 to form an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DDTJ9hvH-Xk3",
    "outputId": "c5d08674-b886-4787-d36b-d22fc55b1f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 28, 28)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(8000, 28,28)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rhFnVp1Pxk56",
    "outputId": "b61004e6-25c1-4fa6-9266-e3e0b88a3c7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 28, 28)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data2.reshape(2000, 28, 28)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5XiKD7sbBfpm"
   },
   "source": [
    "#### Converting the reshaped data to FloatTensor\n",
    "\n",
    "For working with pytorch we need to store everything in FlaotTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeKLjA1ytZNu"
   },
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5c0CrBF7tcWi"
   },
   "outputs": [],
   "source": [
    "data2 = torch.FloatTensor(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-i4mOD8_QT4"
   },
   "source": [
    "## Prepare images for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYeFmV_lBpvy"
   },
   "source": [
    "The class **MyImages** extends the Dataset class of Python and is used to form datasets that can be used by the model. \n",
    "\n",
    "\n",
    "The getitem function returns the image with proper transforms and the correct label.\n",
    "\n",
    "The length function returns the number of items in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7KBtBrwCKDu"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class MyImages(torch.utils.data.Dataset):\n",
    "  \n",
    "  def __init__(self,\n",
    "                 images,\n",
    "                 labels,\n",
    "                 transform=None):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    img, target = self.images[index], self.labels[index]\n",
    "\n",
    "    img = Image.fromarray(img.squeeze().numpy(), mode='F')\n",
    "    \n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)\n",
    "    \n",
    "    return img, target\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __len__(self):\n",
    "        \"\"\"Return size of dataset.\"\"\"\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxKGDBJIOeqE"
   },
   "source": [
    "The class **MyTestImages** extends the Dataset class of Python and is used to form datasets that can be used by the model for test purpose. \n",
    "\n",
    "\n",
    "The getitem function returns the image with proper transforms and the index\n",
    "\n",
    "The length function returns the number of items in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2MrEDsuyP0U"
   },
   "outputs": [],
   "source": [
    "class MyTestImages(torch.utils.data.Dataset):\n",
    "  \n",
    "  def __init__(self,\n",
    "                 images,\n",
    "                 transform=None):\n",
    "    self.images = images\n",
    "    self.transform = transform\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    img, idx = self.images[index], index\n",
    "\n",
    "    img = Image.fromarray(img.squeeze().numpy(), mode='F')\n",
    "    \n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)\n",
    "    \n",
    "    return img, idx\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __len__(self):\n",
    "        \"\"\"Return size of dataset.\"\"\"\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPFjtBIeO3yy"
   },
   "outputs": [],
   "source": [
    "# num of subporcesses for data loading\n",
    "num_workers = 0\n",
    "\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "\n",
    "# percentage of training set to use as validation data\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kq034fboj6H2"
   },
   "source": [
    "Here we are defining the transforms that will be applied on the images and creating the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuTuelLBO_66"
   },
   "outputs": [],
   "source": [
    "# Randomly flip data of train images and convert data to a transfromed torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# The test data need not be flipped\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Dataset for train images\n",
    "train_data = MyImages(data, label, transform = transform)\n",
    "\n",
    "# Dataset for test images\n",
    "test_data = MyTestImages(data2, transform = transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbZcqi6lkYSL"
   },
   "source": [
    "Then we get the indexes that will be used for train data and valid data and create a Random Sampler so that our model does not see the images in same pattern in each epoch. This randomness will prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7XPt_w4PG-2"
   },
   "outputs": [],
   "source": [
    "# obtaining training indices that will be used for validataion\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lbzlrvVk3ZL"
   },
   "source": [
    "#### Creating the loaders\n",
    "\n",
    "Finally we create a data loader to load data in batches for our model. Here we are creating the train loader, valid loader and test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZfZ5i1m-7uH"
   },
   "outputs": [],
   "source": [
    "#Prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          sampler = train_sampler,\n",
    "                                           num_workers = num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          sampler = valid_sampler,\n",
    "                                           num_workers = num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size,\n",
    "                                          num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwFLnesTlNjG"
   },
   "source": [
    "This is not a necessary step, this is just to visualise one batch of the images to understand what our data looks like and also to test if everything so far went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "ufMmnnDk-9u1",
    "outputId": "cc6b810d-27ed-4dfa-d5ac-8166ab418721"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABVYAAAD7CAYAAACBg8+FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERUYv+L9SE8StzZKZfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1800x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images.numpy()\n",
    "\n",
    "\n",
    "# plot the images in the batch\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "for idx in np.arange(16):\n",
    "  ax = fig.add_subplot(2, 16/2, idx + 1, xticks = [], yticks = [])\n",
    "  ax.imshow(np.squeeze(images[idx]))\n",
    "  # print out the correct labels for each image\n",
    "  ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSLKZQWMG5TE"
   },
   "source": [
    "# Defining the Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diadvrr6PUrO"
   },
   "source": [
    "## Basic fully connected layer\n",
    "\n",
    "Since the data is standard greyscale images of MNIST, the first try was a model which flattens the image and works only with fully connected layers.\n",
    "\n",
    "But the problem is that unlike the digits MNIST data, this data is not uniform. Like theres a whitish T-Shirt as well as Greyish one. So, the model fails miserably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "E47KGcApPT4X",
    "outputId": "d8c2d5ec-21e6-44e7-fa93-9e743fb55a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNet(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(FCNet, self).__init__()\n",
    "\n",
    "    # linear layer\n",
    "    self.fc1 = nn.Linear(784, 512)\n",
    "    self.fc2 = nn.Linear(512, 128)    \n",
    "    self.fc3 = nn.Linear(128, 4)\n",
    "    \n",
    "    # dropout layer (p = 0.25)\n",
    "    self.dropout = nn.Dropout(0.25)\n",
    "  \n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, 1 * 28 * 28)\n",
    "    \n",
    "    # add first hidden layer with relu activation\n",
    "    x = F.relu(self.fc1(x))\n",
    "    #add dropout\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    # add second hidden layer\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.fc3(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "#initialize the NN\n",
    "model = FCNet()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AB7pH7LUQPx6"
   },
   "outputs": [],
   "source": [
    "# specify the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify the optimizer and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YicATN3RTSBb"
   },
   "source": [
    "## Simple DL Model \n",
    "\n",
    "The second model I came up with uses 2 units of (Conv, Conv, MaxPool) and then one conv and pool. After this we flatten and pass it through fully connected layers. The conv layer helps identify patterns which were earlier difficult to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "h4F0yC82Tw1f",
    "outputId": "982904ae-1829-408f-9713-28554b1303a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleDLNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1b): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=576, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDLNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleDLNet, self).__init__()\n",
    "     # convolutional layer (sees 28 x 28 x 1 tensor)\n",
    "    self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "    self.conv1b = nn.Conv2d(16, 24, 3, padding = 1)\n",
    "    \n",
    "    # convolutional layer (sees 14 x 14 x 16 tensor)\n",
    "    self.conv2 = nn.Conv2d(24, 32, 3, padding = 1)\n",
    "    self.conv2b = nn.Conv2d(32, 48, 3, padding = 1)\n",
    "    \n",
    "    # convolutional layer (sees 7 x 7 x 48 tensor)\n",
    "    self.conv3 = nn.Conv2d(48, 64, 3, padding = 1)\n",
    "    \n",
    "    # maxpool layers\n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    \n",
    "    # linear layer\n",
    "    self.fc1 = nn.Linear(64 * 3 * 3, 512)\n",
    "    # linear layer (512 -> 128)\n",
    "    self.fc2 = nn.Linear(512, 128)\n",
    "    # linear layer (128 -> 4)\n",
    "    self.fc3 = nn.Linear(128, 4)\n",
    "    \n",
    "    # dropout layer (p = 0.25)\n",
    "    self.dropout = nn.Dropout(0.25)\n",
    "  \n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = self.pool(F.relu(self.conv1b(x)))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = self.pool(F.relu(self.conv2b(x)))\n",
    "    x = self.pool(F.relu(self.conv3(x)))\n",
    "    \n",
    "    # flatten the image\n",
    "    x = x.view(-1, 64 * 3 * 3)\n",
    "    \n",
    "    # add dropout\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    # add first hidden layer with relu activation\n",
    "    x = F.relu(self.fc1(x))\n",
    "    \n",
    "    #add dropout\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    # add second hidden layer\n",
    "    x = F.relu(self.fc2(x))\n",
    "    \n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.fc3(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "#initialize the NN\n",
    "model = SimpleDLNet()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTq-OPc-xRGA"
   },
   "source": [
    "We use Cross Entropy Loss and use SGD(Stochastic gradient descent) as our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKUyBhL4Uejm"
   },
   "outputs": [],
   "source": [
    "# specify the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify the optimizer and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8NAyEXMxktC"
   },
   "source": [
    "#### Training\n",
    "\n",
    "This is the train loop where we save the weights of the model whenever the accuarcy on the validation set tends to increase. This way we can make sure that the weights we are using are the one which maximises accuracy on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "9CfHlA10Qpuy",
    "outputId": "7ec18a06-7d23-4677-e3f1-2e720316988f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.730243 \tValidation Loss: 0.143489 Validation Accuracy 67.56\n",
      "Validation accuracy increased (0.00 --> 67.56).  Saving model ...\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 0.552124 \tValidation Loss: 0.128291 Validation Accuracy 72.19\n",
      "Validation accuracy increased (67.56 --> 72.19).  Saving model ...\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.497627 \tValidation Loss: 0.123485 Validation Accuracy 75.88\n",
      "Validation accuracy increased (72.19 --> 75.88).  Saving model ...\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 0.454002 \tValidation Loss: 0.099610 Validation Accuracy 80.12\n",
      "Validation accuracy increased (75.88 --> 80.12).  Saving model ...\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.415783 \tValidation Loss: 0.099274 Validation Accuracy 80.38\n",
      "Validation accuracy increased (80.12 --> 80.38).  Saving model ...\n",
      "\n",
      "Epoch: 6 \tTraining Loss: 0.383674 \tValidation Loss: 0.091034 Validation Accuracy 82.75\n",
      "Validation accuracy increased (80.38 --> 82.75).  Saving model ...\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 0.362682 \tValidation Loss: 0.093024 Validation Accuracy 80.50\n",
      "\n",
      "Epoch: 8 \tTraining Loss: 0.345706 \tValidation Loss: 0.089686 Validation Accuracy 82.31\n",
      "\n",
      "Epoch: 9 \tTraining Loss: 0.333833 \tValidation Loss: 0.084012 Validation Accuracy 83.00\n",
      "Validation accuracy increased (82.75 --> 83.00).  Saving model ...\n",
      "\n",
      "Epoch: 10 \tTraining Loss: 0.322799 \tValidation Loss: 0.083035 Validation Accuracy 83.50\n",
      "Validation accuracy increased (83.00 --> 83.50).  Saving model ...\n",
      "\n",
      "Epoch: 11 \tTraining Loss: 0.315696 \tValidation Loss: 0.080004 Validation Accuracy 84.19\n",
      "Validation accuracy increased (83.50 --> 84.19).  Saving model ...\n",
      "\n",
      "Epoch: 12 \tTraining Loss: 0.306931 \tValidation Loss: 0.085825 Validation Accuracy 83.75\n",
      "\n",
      "Epoch: 13 \tTraining Loss: 0.289254 \tValidation Loss: 0.079585 Validation Accuracy 83.94\n",
      "\n",
      "Epoch: 14 \tTraining Loss: 0.288712 \tValidation Loss: 0.073211 Validation Accuracy 85.62\n",
      "Validation accuracy increased (84.19 --> 85.62).  Saving model ...\n",
      "\n",
      "Epoch: 15 \tTraining Loss: 0.274289 \tValidation Loss: 0.073002 Validation Accuracy 85.19\n",
      "\n",
      "Epoch: 16 \tTraining Loss: 0.275415 \tValidation Loss: 0.078404 Validation Accuracy 84.81\n",
      "\n",
      "Epoch: 17 \tTraining Loss: 0.260437 \tValidation Loss: 0.075810 Validation Accuracy 85.31\n",
      "\n",
      "Epoch: 18 \tTraining Loss: 0.253208 \tValidation Loss: 0.074626 Validation Accuracy 85.00\n",
      "\n",
      "Epoch: 19 \tTraining Loss: 0.245640 \tValidation Loss: 0.073893 Validation Accuracy 85.62\n",
      "Validation accuracy increased (85.62 --> 85.62).  Saving model ...\n",
      "\n",
      "Epoch: 20 \tTraining Loss: 0.243798 \tValidation Loss: 0.073492 Validation Accuracy 85.62\n",
      "Validation accuracy increased (85.62 --> 85.62).  Saving model ...\n",
      "\n",
      "Epoch: 21 \tTraining Loss: 0.228089 \tValidation Loss: 0.072312 Validation Accuracy 86.00\n",
      "Validation accuracy increased (85.62 --> 86.00).  Saving model ...\n",
      "\n",
      "Epoch: 22 \tTraining Loss: 0.228527 \tValidation Loss: 0.069924 Validation Accuracy 85.88\n",
      "\n",
      "Epoch: 23 \tTraining Loss: 0.221268 \tValidation Loss: 0.071011 Validation Accuracy 84.88\n",
      "\n",
      "Epoch: 24 \tTraining Loss: 0.207695 \tValidation Loss: 0.069851 Validation Accuracy 86.06\n",
      "Validation accuracy increased (86.00 --> 86.06).  Saving model ...\n",
      "\n",
      "Epoch: 25 \tTraining Loss: 0.213416 \tValidation Loss: 0.074720 Validation Accuracy 84.88\n",
      "\n",
      "Epoch: 26 \tTraining Loss: 0.199455 \tValidation Loss: 0.073513 Validation Accuracy 85.81\n",
      "\n",
      "Epoch: 27 \tTraining Loss: 0.196951 \tValidation Loss: 0.067836 Validation Accuracy 86.56\n",
      "Validation accuracy increased (86.06 --> 86.56).  Saving model ...\n",
      "\n",
      "Epoch: 28 \tTraining Loss: 0.194965 \tValidation Loss: 0.068342 Validation Accuracy 87.00\n",
      "Validation accuracy increased (86.56 --> 87.00).  Saving model ...\n",
      "\n",
      "Epoch: 29 \tTraining Loss: 0.184941 \tValidation Loss: 0.071665 Validation Accuracy 86.88\n",
      "\n",
      "Epoch: 30 \tTraining Loss: 0.183447 \tValidation Loss: 0.070383 Validation Accuracy 87.19\n",
      "Validation accuracy increased (87.00 --> 87.19).  Saving model ...\n",
      "\n",
      "Epoch: 31 \tTraining Loss: 0.177125 \tValidation Loss: 0.071939 Validation Accuracy 86.12\n",
      "\n",
      "Epoch: 32 \tTraining Loss: 0.163833 \tValidation Loss: 0.070117 Validation Accuracy 86.94\n",
      "\n",
      "Epoch: 33 \tTraining Loss: 0.167746 \tValidation Loss: 0.068777 Validation Accuracy 87.31\n",
      "Validation accuracy increased (87.19 --> 87.31).  Saving model ...\n",
      "\n",
      "Epoch: 34 \tTraining Loss: 0.164745 \tValidation Loss: 0.069001 Validation Accuracy 87.62\n",
      "Validation accuracy increased (87.31 --> 87.62).  Saving model ...\n",
      "\n",
      "Epoch: 35 \tTraining Loss: 0.152564 \tValidation Loss: 0.068301 Validation Accuracy 88.25\n",
      "Validation accuracy increased (87.62 --> 88.25).  Saving model ...\n",
      "\n",
      "Epoch: 36 \tTraining Loss: 0.154361 \tValidation Loss: 0.074387 Validation Accuracy 86.44\n",
      "\n",
      "Epoch: 37 \tTraining Loss: 0.156430 \tValidation Loss: 0.076905 Validation Accuracy 85.69\n",
      "\n",
      "Epoch: 38 \tTraining Loss: 0.146051 \tValidation Loss: 0.074928 Validation Accuracy 86.94\n",
      "\n",
      "Epoch: 39 \tTraining Loss: 0.155867 \tValidation Loss: 0.071433 Validation Accuracy 87.44\n",
      "\n",
      "Epoch: 40 \tTraining Loss: 0.133964 \tValidation Loss: 0.070237 Validation Accuracy 86.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 40 # you may increase this number to train a final model\n",
    "\n",
    "valid_acc_min = 0 # track change in validation accuracy\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "   \n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    \n",
    "    # train the model #\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "\n",
    "    # validate the model #\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        values, indices = torch.max(output, 1)\n",
    "        correct += torch.sum(indices == target)\n",
    "        total += batch_size\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    accuracy = (float(correct) * 100.0) / float(total)\n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} Validation Accuracy {:.2f}'.format(\n",
    "        epoch, train_loss, valid_loss, accuracy))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if accuracy >= valid_acc_min:\n",
    "        print('Validation accuracy increased ({:.2f} --> {:.2f}).  Saving model ...'.format(\n",
    "        valid_acc_min,\n",
    "        accuracy))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_acc_min = accuracy\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7di3lm4wUpjI"
   },
   "source": [
    "## A Bit Modified DL Network\n",
    "\n",
    "The since the second model is working fine we can up the level by implementing more kernels in each layer of convolutional layer and also increase the numb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "0NGigcms7Bq5",
    "outputId": "74d19c84-a594-47cc-b786-e9eccc9c84cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1b): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2b): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3b): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2b): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DLNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DLNet, self).__init__()\n",
    "     # convolutional layer (sees 28 x 28 x 1 tensor)\n",
    "    self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "    self.conv1b = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "    \n",
    "    # convolutional layer (sees 14 x 14 x 16 tensor)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "    self.conv2b = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "    # convolutional layer (sees 7 x 7 x 32 tensor)\n",
    "    self.conv3 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "    self.conv3b = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "    # maxpool layers\n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    \n",
    "    # linear layer\n",
    "    self.fc1 = nn.Linear(512 * 3 * 3, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 512)\n",
    "    # linear layer (512 -> 10)\n",
    "    self.fc2b = nn.Linear(512, 128)\n",
    "    self.fc3 = nn.Linear(128, 4)\n",
    "    \n",
    "    # dropout layer (p = 0.25)\n",
    "    self.dropout = nn.Dropout(0.25)\n",
    "  \n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = self.pool(F.relu(self.conv1b(x)))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = self.pool(F.relu(self.conv2b(x)))\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x = self.pool(F.relu(self.conv3b(x)))\n",
    "    # flatten the image\n",
    "    x = x.view(-1, 512 * 3 * 3)\n",
    "    \n",
    "    # add dropout\n",
    "    # add first hidden layer with relu activation\n",
    "    x = F.relu(self.fc1(x))\n",
    "    #add dropout\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    # add second hidden layer\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = F.relu(self.fc2b(x))    \n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.fc3(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "#initialize the NN\n",
    "model = DLNet()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lP9cz5AKG8b4"
   },
   "outputs": [],
   "source": [
    "# specify the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify the optimizer and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRKtgyaVx-KJ"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1700
    },
    "colab_type": "code",
    "id": "HjU3gTu4G-_1",
    "outputId": "653a488f-0ea9-400e-cb22-659ad900a275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.945164 \tValidation Loss: 0.182580 Validation Accuracy 59.94\n",
      "Validation accuracy increased (0.00 --> 59.94).  Saving model ...\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 0.650158 \tValidation Loss: 0.145984 Validation Accuracy 66.50\n",
      "Validation accuracy increased (59.94 --> 66.50).  Saving model ...\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.577450 \tValidation Loss: 0.137996 Validation Accuracy 69.94\n",
      "Validation accuracy increased (66.50 --> 69.94).  Saving model ...\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 0.541383 \tValidation Loss: 0.135674 Validation Accuracy 68.75\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.511949 \tValidation Loss: 0.122549 Validation Accuracy 74.06\n",
      "Validation accuracy increased (69.94 --> 74.06).  Saving model ...\n",
      "\n",
      "Epoch: 6 \tTraining Loss: 0.489656 \tValidation Loss: 0.120249 Validation Accuracy 75.69\n",
      "Validation accuracy increased (74.06 --> 75.69).  Saving model ...\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 0.461377 \tValidation Loss: 0.128635 Validation Accuracy 71.69\n",
      "\n",
      "Epoch: 8 \tTraining Loss: 0.440839 \tValidation Loss: 0.115351 Validation Accuracy 75.38\n",
      "\n",
      "Epoch: 9 \tTraining Loss: 0.418872 \tValidation Loss: 0.104667 Validation Accuracy 78.56\n",
      "Validation accuracy increased (75.69 --> 78.56).  Saving model ...\n",
      "\n",
      "Epoch: 10 \tTraining Loss: 0.390637 \tValidation Loss: 0.095957 Validation Accuracy 80.44\n",
      "Validation accuracy increased (78.56 --> 80.44).  Saving model ...\n",
      "\n",
      "Epoch: 11 \tTraining Loss: 0.369032 \tValidation Loss: 0.106119 Validation Accuracy 78.94\n",
      "\n",
      "Epoch: 12 \tTraining Loss: 0.350429 \tValidation Loss: 0.090640 Validation Accuracy 80.50\n",
      "Validation accuracy increased (80.44 --> 80.50).  Saving model ...\n",
      "\n",
      "Epoch: 13 \tTraining Loss: 0.342061 \tValidation Loss: 0.086375 Validation Accuracy 82.69\n",
      "Validation accuracy increased (80.50 --> 82.69).  Saving model ...\n",
      "\n",
      "Epoch: 14 \tTraining Loss: 0.327378 \tValidation Loss: 0.085164 Validation Accuracy 83.00\n",
      "Validation accuracy increased (82.69 --> 83.00).  Saving model ...\n",
      "\n",
      "Epoch: 15 \tTraining Loss: 0.313345 \tValidation Loss: 0.094466 Validation Accuracy 81.94\n",
      "\n",
      "Epoch: 16 \tTraining Loss: 0.300259 \tValidation Loss: 0.087102 Validation Accuracy 82.50\n",
      "\n",
      "Epoch: 17 \tTraining Loss: 0.296256 \tValidation Loss: 0.080153 Validation Accuracy 83.88\n",
      "Validation accuracy increased (83.00 --> 83.88).  Saving model ...\n",
      "\n",
      "Epoch: 18 \tTraining Loss: 0.286228 \tValidation Loss: 0.081439 Validation Accuracy 83.25\n",
      "\n",
      "Epoch: 19 \tTraining Loss: 0.275493 \tValidation Loss: 0.083803 Validation Accuracy 84.75\n",
      "Validation accuracy increased (83.88 --> 84.75).  Saving model ...\n",
      "\n",
      "Epoch: 20 \tTraining Loss: 0.270734 \tValidation Loss: 0.084789 Validation Accuracy 84.50\n",
      "\n",
      "Epoch: 21 \tTraining Loss: 0.266788 \tValidation Loss: 0.079067 Validation Accuracy 84.75\n",
      "Validation accuracy increased (84.75 --> 84.75).  Saving model ...\n",
      "\n",
      "Epoch: 22 \tTraining Loss: 0.255884 \tValidation Loss: 0.085390 Validation Accuracy 83.44\n",
      "\n",
      "Epoch: 23 \tTraining Loss: 0.243397 \tValidation Loss: 0.076465 Validation Accuracy 85.00\n",
      "Validation accuracy increased (84.75 --> 85.00).  Saving model ...\n",
      "\n",
      "Epoch: 24 \tTraining Loss: 0.239421 \tValidation Loss: 0.075946 Validation Accuracy 86.00\n",
      "Validation accuracy increased (85.00 --> 86.00).  Saving model ...\n",
      "\n",
      "Epoch: 25 \tTraining Loss: 0.227905 \tValidation Loss: 0.079868 Validation Accuracy 85.94\n",
      "\n",
      "Epoch: 26 \tTraining Loss: 0.222450 \tValidation Loss: 0.073012 Validation Accuracy 86.56\n",
      "Validation accuracy increased (86.00 --> 86.56).  Saving model ...\n",
      "\n",
      "Epoch: 27 \tTraining Loss: 0.213982 \tValidation Loss: 0.071491 Validation Accuracy 86.19\n",
      "\n",
      "Epoch: 28 \tTraining Loss: 0.204863 \tValidation Loss: 0.072532 Validation Accuracy 85.81\n",
      "\n",
      "Epoch: 29 \tTraining Loss: 0.206373 \tValidation Loss: 0.074804 Validation Accuracy 86.06\n",
      "\n",
      "Epoch: 30 \tTraining Loss: 0.194107 \tValidation Loss: 0.072824 Validation Accuracy 86.50\n",
      "\n",
      "Epoch: 31 \tTraining Loss: 0.177226 \tValidation Loss: 0.073802 Validation Accuracy 86.56\n",
      "Validation accuracy increased (86.56 --> 86.56).  Saving model ...\n",
      "\n",
      "Epoch: 32 \tTraining Loss: 0.178306 \tValidation Loss: 0.075730 Validation Accuracy 86.56\n",
      "Validation accuracy increased (86.56 --> 86.56).  Saving model ...\n",
      "\n",
      "Epoch: 33 \tTraining Loss: 0.164103 \tValidation Loss: 0.076281 Validation Accuracy 85.56\n",
      "\n",
      "Epoch: 34 \tTraining Loss: 0.153298 \tValidation Loss: 0.076513 Validation Accuracy 86.75\n",
      "Validation accuracy increased (86.56 --> 86.75).  Saving model ...\n",
      "\n",
      "Epoch: 35 \tTraining Loss: 0.154153 \tValidation Loss: 0.086267 Validation Accuracy 85.56\n",
      "\n",
      "Epoch: 36 \tTraining Loss: 0.140669 \tValidation Loss: 0.081619 Validation Accuracy 86.31\n",
      "\n",
      "Epoch: 37 \tTraining Loss: 0.138333 \tValidation Loss: 0.089265 Validation Accuracy 84.69\n",
      "\n",
      "Epoch: 38 \tTraining Loss: 0.135881 \tValidation Loss: 0.093356 Validation Accuracy 84.69\n",
      "\n",
      "Epoch: 39 \tTraining Loss: 0.124016 \tValidation Loss: 0.087074 Validation Accuracy 85.25\n",
      "\n",
      "Epoch: 40 \tTraining Loss: 0.121518 \tValidation Loss: 0.080733 Validation Accuracy 86.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 40 # you may increase this number to train a final model\n",
    "\n",
    "valid_acc_min = 0 # track change in validation accuracy\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "   \n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    \n",
    "    # train the model #\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "\n",
    "    # validate the model #\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        values, indices = torch.max(output, 1)\n",
    "        correct += torch.sum(indices == target)\n",
    "        total += batch_size\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    accuracy = (float(correct) * 100.0) / float(total)\n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} Validation Accuracy {:.2f}'.format(\n",
    "        epoch, train_loss, valid_loss, accuracy))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if accuracy >= valid_acc_min:\n",
    "        print('Validation accuracy increased ({:.2f} --> {:.2f}).  Saving model ...'.format(\n",
    "        valid_acc_min,\n",
    "        accuracy))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_acc_min = accuracy\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFpIwDCbxH7z"
   },
   "source": [
    "## Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjyUpaWX-Ht_"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgYmBo-wyDcB"
   },
   "source": [
    "Placeholders to contain the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyBXb0Fg0bGr"
   },
   "outputs": [],
   "source": [
    "image_index = []\n",
    "image_label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0gn6ZTTyGC2"
   },
   "source": [
    "### Predicting for test images\n",
    "\n",
    "Since now we are preparing for submission we set the model to evaluate mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nH1hSb6sxZWV"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "   \n",
    "    size = len(pred)\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(size):\n",
    "        label = pred[i]\n",
    "        image_index.append(target[i].cpu().numpy().item())\n",
    "        image_label.append(label.cpu().numpy().item())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtwHdBkcqXuD"
   },
   "outputs": [],
   "source": [
    "plot_label = np.array(image_label)\n",
    "plot_label[plot_label == 1] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9m_na25HmKs"
   },
   "outputs": [],
   "source": [
    "plot_index = np.array(image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b19OoAIb9BjZ",
    "outputId": "33f1b4ce-b904-4052-a433-d95924b58ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(plot_label[:501] == 0) + np.sum(plot_label[500:1001] == 2) + np.sum(plot_label[1000:1501] == 3) + np.sum(plot_label[1500:] == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLeHy4LuucHv"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'class':plot_label, 'image_index':plot_index})\n",
    "df = df[df.columns[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsgvcDCQqB7H"
   },
   "outputs": [],
   "source": [
    "df.to_csv('rahul.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt_qykO5-76x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIIT_Delhi.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
